{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ReorgModule(nn.Module):\n",
    "    def __init__(self, stride=2):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "    def forward(self, x):\n",
    "        stride = self.stride\n",
    "        assert(x.data.dim() == 4)\n",
    "        B, C, H, W = x.shape\n",
    "        assert(H % stride == 0)\n",
    "        assert(W % stride == 0)\n",
    "        ws = stride\n",
    "        hs = stride\n",
    "        x = x.view(B, C, H//hs, hs, W//ws, ws).transpose(3,4).contiguous()\n",
    "        x = x.view(B, C, H//hs*W//ws, hs*ws).transpose(2,3).contiguous()\n",
    "        x = x.view(B, C, hs*ws, H//hs, W//ws).transpose(1,2).contiguous()\n",
    "        x = x.view(B, hs*ws*C, H//hs, W//ws)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _RegionModule(nn.Module):\n",
    "    def __init__(self, anchors):\n",
    "        super().__init__()\n",
    "        self.anchors = anchors\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _EmptyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _RouteModule(nn.Module):\n",
    "    def __init__(self, start, end=None):\n",
    "        super().__init__()\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "    def forward(self, x, outputs, idx):\n",
    "        map1 = outputs[idx + self.start]\n",
    "        if self.end:\n",
    "            map2 = outputs[idx + self.end]\n",
    "            return torch.cat([map1, map2], 1)\n",
    "        return map1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _MaxPoolStride1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(_MaxPoolStride1, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.pad(x, (0,1,0,1), mode='replicate'), 2, stride=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform_predictions(preds, inp_size, anchors, num_classes, device):\n",
    "    N, C, H, W = preds.shape\n",
    "    grid_size = H\n",
    "    stride = inp_size // grid_size\n",
    "    num_anchors = len(anchors)\n",
    "    bbox_attrs = num_classes + 5\n",
    "\n",
    "\n",
    "    preds = preds.view(N, bbox_attrs*num_anchors, grid_size*grid_size) #This seems to be the same as preds.view(N, C, H*W)\n",
    "    preds = preds.permute(0, 2, 1).contiguous()                        #N, (H*W), (5+C)*n_anchors\n",
    "    preds = preds.view(N, grid_size*grid_size*num_anchors, bbox_attrs) #N, (H*W)*n_anchors, (5+C)\n",
    "\n",
    "    #anchors = [(a[0]/stride, a[1]/stride) for a in anchors]\n",
    "\n",
    "    #Sigmoid the center_x, center_y and object confidence\n",
    "    preds[..., :2] = torch.sigmoid(preds[..., :2])\n",
    "    obj_probs = torch.sigmoid(preds[..., 4])\n",
    "\n",
    "    #Add the grid offsets to the center coordinates prediction\n",
    "    grid = np.arange(grid_size)\n",
    "    x_offsets, y_offsets = np.meshgrid(grid, grid)\n",
    "\n",
    "    x_offsets = torch.tensor(x_offsets, dtype=torch.float, device=device).view(-1, 1) #a column vector\n",
    "    y_offsets = torch.tensor(y_offsets, dtype=torch.float, device=device).view(-1, 1) #a column vector\n",
    "\n",
    "    x_y_offsets = torch.cat([x_offsets, y_offsets], 1).repeat(1, num_anchors).view(-1, 2).unsqueeze(0)\n",
    "\n",
    "    preds[..., :2] += x_y_offsets #at this stage, (bx = sigmoid(tx) + cx ) and (by = sigmoid(ty) + cy) is done\n",
    "\n",
    "    #Now that we're done with the center coordinates of the bounding boxes, let's process the widths and heights of them.\n",
    "    #Apply the anchors to the dimensions of the bounding box.\n",
    "    #log space transform height and width\n",
    "    anchors = torch.tensor(anchors, dtype=torch.float, device=device)\n",
    "    anchors = anchors.repeat(grid_size*grid_size, 1).unsqueeze(0)\n",
    "    preds[..., 2:4] = torch.exp(preds[..., 2:4])*anchors\n",
    "\n",
    "    #Now we'are done with the center of the boxes and the height and width of the boxes.\n",
    "    #Let's now apply softmax function to the class scores.\n",
    "    #class_probs = F.softmax(preds[..., 5:], -1)\n",
    "    class_scores = preds[..., 5:]\n",
    "\n",
    "    #Resize detection map to the size of the input image\n",
    "    boxes = preds[..., :4]*stride\n",
    "\n",
    "    #return preds #(center_x, center_y, height, width)\n",
    "    return boxes, obj_probs, class_scores #(center_x, center_y, height, width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_cfg_lines(cfgfile):\n",
    "    with open(cfgfile, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        lines = list(filter(None, lines)) #remove empty lines\n",
    "        lines = [l for l in lines if l[0] != '#']\n",
    "        lines = [x.strip() for x in lines] #get rid of whitespaces\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_block_dicts(lines):\n",
    "    block, blocks = {}, []\n",
    "    for line in lines:\n",
    "        if line[0] == '[':                              #This marks the start of a new block\n",
    "            if len(block) != 0:                         #If block is not empty, implies it is storing values of previous block.\n",
    "                blocks.append(block)                    #Add it to the block list\n",
    "                block = {}                              #Re-init the block.\n",
    "            block['type'] = line[1:-1].strip()\n",
    "        else:\n",
    "            key, value = line.split('=')\n",
    "            block[key.strip()] = value.strip()\n",
    "\n",
    "    blocks.append(block)\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_conv_module(idx, block, prev_filters):\n",
    "    module = nn.Sequential()\n",
    "    activation = block['activation']\n",
    "    batch_normalize = block.get('batch_normalize')\n",
    "    filters = int(block['filters'])\n",
    "    padding = int(block['pad'])\n",
    "    kernel_size = int(block['size'])\n",
    "    stride = int(block['stride'])\n",
    "\n",
    "    if padding:\n",
    "        pad = (kernel_size - 1) // 2\n",
    "    else:\n",
    "        pad = 0\n",
    "\n",
    "    conv = nn.Conv2d(in_channels=prev_filters, out_channels=filters, kernel_size=kernel_size,\n",
    "                     stride=stride, padding=pad, bias=False if batch_normalize else True)\n",
    "    module.add_module(\"conv_{0}\".format(idx), conv)\n",
    "\n",
    "    if batch_normalize:\n",
    "        bn = nn.BatchNorm2d(filters)\n",
    "        module.add_module(\"batch_norm_{0}\".format(idx), bn)\n",
    "\n",
    "    #Activation is either Linear or a Leaky ReLU for YOLO\n",
    "    if activation == 'leaky':\n",
    "        leaky_relu = nn.LeakyReLU(0.1, inplace=True)\n",
    "        module.add_module(\"leaky_{0}\".format(idx), leaky_relu)\n",
    "\n",
    "    return module, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_maxpool_module(block):\n",
    "    #Both YOLO f/ PASCAL and COCO don't use 2X2 pooling with stride 1\n",
    "    #Tiny-YOLO does use it\n",
    "    kernel_size = int(block['size'])\n",
    "    stride = int(block['stride'])\n",
    "\n",
    "    if stride > 1:\n",
    "        pool = nn.MaxPool2d(kernel_size, stride=stride)\n",
    "    else:\n",
    "        pool = _MaxPoolStride1()\n",
    "\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_region_block(block, net_info):\n",
    "    anchors = block['anchors'].split(',')\n",
    "    anchors = [float(a) for a in anchors]\n",
    "    anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors), 2)]\n",
    "\n",
    "    net_info['anchors'] = anchors\n",
    "    net_info['num_classes'] = int(block['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_region_module(block):\n",
    "    anchors = block['anchors'].split(',')\n",
    "    anchors = [float(a) for a in anchors]\n",
    "    anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors), 2)]\n",
    "\n",
    "    region = _RegionModule(anchors)\n",
    "\n",
    "    return region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_route_module(idx, block, output_filters):\n",
    "    block['layers'] = [int(l) for l in block['layers'].split(',')]\n",
    "    start = block['layers'][0]\n",
    "    #end, if there exists one\n",
    "    if len(block['layers']) > 1:\n",
    "        end = block['layers'][1]\n",
    "    else:\n",
    "        end = 0 #0 means that we should stay on the current layer. There is no route.\n",
    "\n",
    "    #Positive annotation\n",
    "    if start > 0:\n",
    "        start = start - idx\n",
    "    if end > 0:\n",
    "        end = end - idx\n",
    "\n",
    "    if end < 0:\n",
    "        filters = output_filters[idx + start] + output_filters[idx + end]\n",
    "    else:\n",
    "        filters = output_filters[idx + start]\n",
    "\n",
    "    module = _RouteModule(start, end)\n",
    "\n",
    "    return module, filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_reorg_module(block, prev_filters):\n",
    "    stride = int(block['stride'])\n",
    "    reorg = _ReorgModule(stride)\n",
    "    prev_filters = stride*stride*prev_filters\n",
    "    return reorg, prev_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_cfg(cfgfile):\n",
    "    \"\"\"\n",
    "    Takes a configuration file\n",
    "\n",
    "    Returns a list of blocks. Each block describes a block in the neural\n",
    "    network to be built. Block is represented as a dictionary in the list.\n",
    "    \"\"\"\n",
    "    lines = _read_cfg_lines(cfgfile)\n",
    "    blocks =_create_block_dicts(lines)\n",
    "    return blocks\n",
    "def _create_modules(block_dicts):\n",
    "    net_info = block_dicts[0]       #Captures the 'net' block, which has information about the input and pre-processing\n",
    "    module_list = nn.ModuleList()\n",
    "    prev_filters = 3                #We initialize this to 3 since the image has 3 channels\n",
    "    output_filters = []\n",
    "\n",
    "    for idx, block in enumerate(block_dicts[1:]):\n",
    "        if block['type'] == 'convolutional':\n",
    "            module, prev_filters = _make_conv_module(idx, block, prev_filters)\n",
    "        elif block['type'] == 'maxpool':\n",
    "            module = _make_maxpool_module(block)\n",
    "        elif block['type'] == 'shortcut':\n",
    "            module = _EmptyModule()\n",
    "        elif block['type'] == 'route':\n",
    "            module, prev_filters = _make_route_module(idx, block, output_filters)\n",
    "        elif block['type'] == 'reorg':\n",
    "            module, prev_filters = _make_reorg_module(block, prev_filters)\n",
    "        elif block['type'] == 'region':\n",
    "            _read_region_block(block, net_info)\n",
    "            break\n",
    "            #module = _make_region_module(block)\n",
    "\n",
    "        module_list.append(module)\n",
    "        output_filters.append(prev_filters)\n",
    "\n",
    "    return module_list, net_info    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "    def __init__(self, cfgfile, device, input_size=None):\n",
    "        super().__init__()\n",
    "        self.block_dicts = _parse_cfg(cfgfile)\n",
    "        self.module_list, self.net_info = _create_modules(self.block_dicts)\n",
    "        self.device = device\n",
    "        if input_size is not None:\n",
    "            self.input_size = input_size\n",
    "        else:\n",
    "            self.input_size = int(self.net_info['height'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = {} #We cache the outputs since route and shortcut layers will need them\n",
    "        for i, block in enumerate(self.block_dicts[1:-1]): #blocks except net block and region block\n",
    "            if block['type'] in ('convolutional', 'maxpool', 'reorg'):\n",
    "                x = self.module_list[i](x)\n",
    "            elif block['type'] == 'route':\n",
    "                x = self.module_list[i](x, outputs, i)\n",
    "            elif block['type'] == 'shortcut':\n",
    "                from_ = int(block['from'])\n",
    "                x = outputs[i-1] + outputs[i + from_]\n",
    "            outputs[i] = x\n",
    "\n",
    "        boxes, obj_probs, class_probs = _transform_predictions(x, self.input_size, self.net_info['anchors'],\n",
    "                                        self.net_info['num_classes'], self.device)\n",
    "\n",
    "        return boxes, obj_probs, class_probs\n",
    "    def load_weights(self, weightfile):\n",
    "        #The first 5 values are header information (These might not be correct.)\n",
    "        # 1. Major version number\n",
    "        # 2. Minor version number\n",
    "        # 3. Subversion number\n",
    "        # 4 Images seen by the network (during training)\n",
    "        with open(weightfile) as f:\n",
    "            header = np.fromfile(f, dtype=np.int32, count=4)\n",
    "            self.header = torch.tensor(header, dtype=torch.int)\n",
    "            self.seen = self.header[3]\n",
    "            weights =  np.fromfile(f, dtype=np.float32)\n",
    "        ptr = 0\n",
    "        for i in range(len(self.module_list)):\n",
    "            module_type = self.block_dicts[i+1]['type'] #i+1 because this includes the 'net' block\n",
    "            if module_type == 'convolutional':\n",
    "                module = self.module_list[i]\n",
    "                batch_normalize = self.block_dicts[i+1].get('batch_normalize')  #i+1 because this includes the 'net' block\n",
    "                conv = module[0]\n",
    "\n",
    "                if batch_normalize:\n",
    "                    bn = module[1]\n",
    "\n",
    "                    #Get the number of weights of the Batch Norm Layer\n",
    "                    num_bn_biases = bn.bias.numel()\n",
    "\n",
    "                    #Load the weights\n",
    "                    bn_biases = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "\n",
    "                    bn_weights = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "\n",
    "                    bn_running_mean = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "\n",
    "                    bn_running_var = torch.from_numpy(weights[ptr:ptr+num_bn_biases])\n",
    "                    ptr += num_bn_biases\n",
    "\n",
    "                    #Convert the shape of the loaded weights to those of the model's\n",
    "                    bn_biases = bn_biases.view_as(bn.bias.detach())\n",
    "                    bn_weights = bn_weights.view_as(bn.weight.detach())\n",
    "                    bn_running_mean = bn_running_mean.view_as(bn.running_mean)\n",
    "                    bn_running_var = bn_running_var.view_as(bn.running_var)\n",
    "\n",
    "                    #Copy the datasets to model\n",
    "                    bn.bias.data.copy_(bn_biases)\n",
    "                    bn.weight.data.copy_(bn_weights)\n",
    "                    bn.running_mean.copy_(bn_running_mean)\n",
    "                    bn.running_var.copy_(bn_running_var)\n",
    "                else:\n",
    "                    #Number of biases\n",
    "                    num_biases = conv.bias.numel()\n",
    "\n",
    "                    #Load the weights\n",
    "                    conv_biases = torch.from_numpy(weights[ptr:ptr+num_biases])\n",
    "                    ptr += num_biases\n",
    "\n",
    "                    #Reshape the loaded weigths according to the dims of the model weights\n",
    "                    conv_biases = conv_biases.view_as(conv.bias.data)\n",
    "\n",
    "                    #Finally copy the datasets\n",
    "                    conv.bias.data.copy_(conv_biases)\n",
    "\n",
    "                #Load the weights for the convolutional layers\n",
    "                num_weights = conv.weight.numel()\n",
    "\n",
    "                #Do the same as above for weights\n",
    "                conv_weights = torch.from_numpy(weights[ptr:ptr+num_weights])\n",
    "                ptr += num_weights\n",
    "\n",
    "                conv_weights = conv_weights.view_as(conv.weight.data)\n",
    "                conv.weight.data.copy_(conv_weights)\n",
    "\n",
    "    def full_forward(self, x):\n",
    "        boxes, obj_probs, class_scores = self.forward(x)\n",
    "        return boxes, obj_probs, torch.softmax(class_scores, -1)\n",
    "\n",
    "    def visualize(self, data, cats, threshold=0.5, nms_threshold=0.5, num_images=9, figsize=(20,20)):\n",
    "        i = 0\n",
    "        plot_size = np.sqrt(num_images)\n",
    "        if not float.is_integer(plot_size):\n",
    "            plot_size +=1\n",
    "        plot_size = int(plot_size)\n",
    "        fig, axs = plt.subplots(ncols=plot_size, nrows=plot_size, figsize=figsize)\n",
    "        for (x, _) in data.val_dl:\n",
    "            inp = x.to(self.device)\n",
    "            p_boxes_b, p_obj_probs_b, p_class_probs_b =  self.full_forward(inp)\n",
    "            for (im, p_boxes, p_obj_probs, p_class_probs) in zip(inp, p_boxes_b, p_obj_probs_b, p_class_probs_b):\n",
    "                detections = detector.filter_predictions(p_boxes, p_obj_probs, p_class_probs, cats,\n",
    "                                                         threshold=threshold, nms_threshold=nms_threshold)\n",
    "                ax = axs.flat[i]\n",
    "                ax.axis('off')\n",
    "                im = data.denorm(im)\n",
    "                im = im.clip(0, 1)\n",
    "\n",
    "                out_img = detector.draw_predictions(im, detections)\n",
    "                out_img = out_img.clip(0, 1)\n",
    "                ax.imshow(out_img)\n",
    "                i+= 1\n",
    "                if i == num_images:\n",
    "                    for j in range(i, plot_size*plot_size):\n",
    "                        fig.delaxes(axs.flat[j])\n",
    "                    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
